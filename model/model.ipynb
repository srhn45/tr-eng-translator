{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m     31\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 33\u001b[0m count_token_lengths(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/tokenized_data_train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m, in \u001b[0;36mcount_token_lengths\u001b[1;34m(filepath, chunksize, max_tokens)\u001b[0m\n\u001b[0;32m      8\u001b[0m counter \u001b[38;5;241m=\u001b[39m Counter()\n\u001b[0;32m      9\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(filepath, usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m], chunksize\u001b[38;5;241m=\u001b[39mchunksize):\n\u001b[0;32m     12\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m chunk[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     13\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m lengths[lengths \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_tokens]  \u001b[38;5;66;03m# Filter out long sequences\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\takns\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1843\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   1842\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1843\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_chunk()\n\u001b[0;32m   1844\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\takns\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1985\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1983\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m   1984\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[1;32m-> 1985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nrows\u001b[38;5;241m=\u001b[39msize)\n",
      "File \u001b[1;32mc:\\Users\\takns\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\takns\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:236\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    234\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\takns\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:355\u001b[0m, in \u001b[0;36m_concatenate_chunks\u001b[1;34m(chunks)\u001b[0m\n\u001b[0;32m    348\u001b[0m             values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_date_conv(\n\u001b[0;32m    349\u001b[0m                 values,\n\u001b[0;32m    350\u001b[0m                 col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_names[index] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    351\u001b[0m             )\n\u001b[0;32m    352\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_concatenate_chunks\u001b[39m(chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, ArrayLike]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m    356\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03m    Concatenate chunks of data read with low_memory=True.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m    The tricky part is handling Categoricals, where different chunks\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;124;03m    may have different inferred categories.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    362\u001b[0m     names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# to see the data distribution\n",
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def count_token_lengths(filepath, chunksize=100_000, max_tokens=50):\n",
    "    counter = Counter()\n",
    "    total = 0\n",
    "\n",
    "    for chunk in pd.read_csv(filepath, usecols=[\"input_ids\"], chunksize=chunksize):\n",
    "        lengths = chunk[\"input_ids\"].str.count(\" \") + 1\n",
    "        lengths = lengths[lengths <= max_tokens]  # Filter out long sequences\n",
    "        counter.update(lengths)\n",
    "        total += len(chunk)\n",
    "\n",
    "    print(f\"\\nFinal counts by token length (≤ {max_tokens}):\")\n",
    "    for length in sorted(counter):\n",
    "        print(f\"Length {length}: {counter[length]:,}\")\n",
    "\n",
    "    lengths = list(counter.keys())\n",
    "    counts = list(counter.values())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(lengths, counts)\n",
    "    plt.xlabel(\"Token Length\")\n",
    "    plt.ylabel(\"Number of Samples\")\n",
    "    plt.title(f\"Distribution of Token Lengths ≤ {max_tokens}\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "count_token_lengths(\"../data/tokenized_data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final counts by token length (≤ 30):\n",
      "Length 3: 61\n",
      "Length 4: 1,428\n",
      "Length 5: 4,402\n",
      "Length 6: 8,988\n",
      "Length 7: 13,869\n",
      "Length 8: 17,306\n",
      "Length 9: 19,208\n",
      "Length 10: 20,087\n",
      "Length 11: 19,256\n",
      "Length 12: 18,283\n",
      "Length 13: 17,790\n",
      "Length 14: 16,827\n",
      "Length 15: 15,867\n",
      "Length 16: 14,672\n",
      "Length 17: 13,576\n",
      "Length 18: 12,725\n",
      "Length 19: 11,859\n",
      "Length 20: 10,978\n",
      "Length 21: 10,320\n",
      "Length 22: 9,655\n",
      "Length 23: 9,158\n",
      "Length 24: 8,608\n",
      "Length 25: 8,229\n",
      "Length 26: 7,859\n",
      "Length 27: 7,493\n",
      "Length 28: 7,294\n",
      "Length 29: 7,057\n",
      "Length 30: 6,784\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_token_lengths(\"../data/tokenized_data_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler\n",
    "import tqdm\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import os, requests, json\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "import sentencepiece as spm\n",
    "import random\n",
    "import sacrebleu\n",
    "#import multiprocessing\n",
    "#from transformers import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  \n",
    "\n",
    "WEBHOOK = os.getenv(\"DISCORD_WEBHOOK_URL\")\n",
    "if not WEBHOOK:\n",
    "    raise RuntimeError(\"Please create a .env with DISCORD_WEBHOOK_URL\") # i didn't want to bother making it optional, sorry\n",
    "TELEGRAM_TOKEN = os.getenv(\"TELEGRAM_BOT_TOKEN\")\n",
    "TELEGRAM_CHAT_ID = os.getenv(\"TELEGRAM_CHAT_ID\")\n",
    "if not TELEGRAM_TOKEN or not TELEGRAM_CHAT_ID:\n",
    "    raise RuntimeError(\"Please create a .env with TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID\") # same as above\n",
    "\n",
    "def send_discord(content: str=None, embed: dict=None, tqdm_obj=None): # to track training progress on my phone when i'm away from my computer\n",
    "    if tqdm_obj is not None:\n",
    "        processed = tqdm_obj.n\n",
    "        total = tqdm_obj.total\n",
    "        time = tqdm_obj.format_dict[\"elapsed\"]\n",
    "\n",
    "        if total > 0:\n",
    "            percentage = (processed / total) * 100\n",
    "        else:\n",
    "            percentage = 0\n",
    "\n",
    "        content = f\"Progress: {processed}/{total} ({percentage:.2f}%) \\n Elapsed time: {time/60:.1f}s \\n Rate: {processed / time:.2f} items/s\"\n",
    "\n",
    "    payload = {}\n",
    "    if content:\n",
    "        payload[\"content\"] = content\n",
    "    if embed:\n",
    "        payload[\"embeds\"] = [embed]\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    try:\n",
    "        resp = requests.post(WEBHOOK,\n",
    "                            data=json.dumps(payload),\n",
    "                            headers=headers,\n",
    "                            timeout=5)\n",
    "        resp.raise_for_status() # check for HTTP errors\n",
    "    except Exception as e:\n",
    "        pass # since discord is banned in turkey (yay), i just want this to fail silently for now. maybe one day it'll start working again..\n",
    "\n",
    "\n",
    "def send_telegram(content: str = None, embed: dict = None, tqdm_obj=None):\n",
    "    if tqdm_obj is not None:\n",
    "        processed = tqdm_obj.n\n",
    "        total = tqdm_obj.total\n",
    "        time = tqdm_obj.format_dict[\"elapsed\"]\n",
    "\n",
    "        if total > 0:\n",
    "            percentage = (processed / total) * 100\n",
    "        else:\n",
    "            percentage = 0\n",
    "\n",
    "        content = f\"Progress: {processed}/{total} ({percentage:.2f}%) \\n Elapsed time: {time/60:.1f}m \\n Rate: {processed / time:.2f} items/s\"\n",
    "\n",
    "    if embed:\n",
    "        lines = []\n",
    "        if 'title' in embed:\n",
    "            lines.append(f\"<b>{embed['title']}</b>\")\n",
    "\n",
    "        for field in embed.get(\"fields\", []):\n",
    "            name = field.get(\"name\", \"\")\n",
    "            value = field.get(\"value\", \"\")\n",
    "            lines.append(f\"<b>{name}:</b> {value}\")\n",
    "\n",
    "        if content:\n",
    "            lines.append(\"\")  # add a newline\n",
    "            lines.append(content)\n",
    "\n",
    "        content = \"\\n\".join(lines)\n",
    "\n",
    "    if not content:\n",
    "        return  # nothing to send\n",
    "\n",
    "    url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
    "    payload = {\n",
    "        \"chat_id\": TELEGRAM_CHAT_ID,\n",
    "        \"text\": content,\n",
    "        \"parse_mode\": \"HTML\"\n",
    "    }\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    try:\n",
    "        resp = requests.post(url, json=payload, headers=headers, timeout=5)\n",
    "        resp.raise_for_status()\n",
    "    except Exception as e_direct:\n",
    "        print(f\"❌ Telegram error: {e_direct}\")\n",
    "\n",
    "\n",
    "def send_message(content: str = None, embed: dict = None, tqdm_obj=None):\n",
    "    send_discord(content=content, embed=embed, tqdm_obj=tqdm_obj)\n",
    "    send_telegram(content=content, embed=embed, tqdm_obj=tqdm_obj)\n",
    "\n",
    "\n",
    "def make_embed(epoch, train_loss, val_loss, lr, done_steps, max_tokens, batches_per_size):\n",
    "    e = {\n",
    "      \"title\": f\"Epoch {epoch} Complete 🎉\",\n",
    "      \"color\": 0x56B4E9,\n",
    "      \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "      \"fields\": [\n",
    "        {\"name\": \"Train Loss\", \"value\": f\"{train_loss:.4f}\", \"inline\": True},\n",
    "        {\"name\": \"Val Loss\",   \"value\": f\"{val_loss:.4f}\",   \"inline\": True},\n",
    "        {\"name\": \"LR\",         \"value\": f\"{lr:.8f}\",         \"inline\": True},\n",
    "        {\"name\": \"Step\",       \"value\": f\"{done_steps}\",     \"inline\": True},\n",
    "        {\"name\": \"Max Tokens\", \"value\": f\"{max_tokens}\",     \"inline\": True},\n",
    "        {\"name\": \"Batches/Size\", \"value\": f\"{batches_per_size}\", \"inline\": True},\n",
    "      ]\n",
    "    }\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high') # for better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens_fast(s):\n",
    "    return s.str.count(\" \") + 1 # this is lightspeed, gamechanger for me\n",
    "\n",
    "def parse_string(s):\n",
    "    return s.str.split().apply(lambda x: np.array([int(tok) for tok in x if tok.isdigit()], dtype=np.int32))\n",
    "\n",
    "class DatasetFromCSV(Dataset):\n",
    "    def __init__(self, filepath, mode=\"train\", batches_per_size=3000, max_tokens=15, batch_size=16):\n",
    "        \n",
    "        if mode == \"val\":\n",
    "            max_tokens = 40\n",
    "            batches_per_size = 500\n",
    "\n",
    "        df = pd.read_csv(filepath, usecols=[\"input_ids\", \"label_ids\"])\n",
    "        df[\"length\"] = df[\"input_ids\"].str.count(\" \") + 1\n",
    "        df = df[df[\"length\"] <= max_tokens].copy()\n",
    "\n",
    "\n",
    "        df[\"parsed_input_ids\"] = parse_string(df[\"input_ids\"])\n",
    "        df[\"parsed_label_ids\"] = parse_string(df[\"label_ids\"])\n",
    "\n",
    "        max_examples_per_length = batches_per_size * batch_size\n",
    "\n",
    "        selected_input_ids = []\n",
    "        selected_label_ids = []\n",
    "\n",
    "        for length in range(1, max_tokens + 1):\n",
    "            group = df[df[\"length\"] == length]\n",
    "            if len(group) == 0:\n",
    "                continue\n",
    "            sampled = group.sample(n=min(len(group), max_examples_per_length))\n",
    "            selected_input_ids.extend(sampled[\"parsed_input_ids\"].tolist())\n",
    "            selected_label_ids.extend(sampled[\"parsed_label_ids\"].tolist())\n",
    "\n",
    "        self.input_ids = selected_input_ids\n",
    "        self.label_ids = selected_label_ids\n",
    "        \n",
    "\n",
    "        if mode == \"train\":\n",
    "            print(f\"[DatasetFromCSV] Loaded {len(selected_input_ids)} examples up to {max((len(seq) for seq in self.input_ids), default=0)} tokens from {min((len(seq) for seq in self.input_ids), default=0)}.\")\n",
    "            send_message(content=f\"[DatasetFromCSV] Loaded {len(selected_input_ids)} examples up to {max((len(seq) for seq in self.input_ids), default=0)} tokens from {min((len(seq) for seq in self.input_ids), default=0)}.\")\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "                \"input_ids\": torch.from_numpy(self.input_ids[idx]).long(),\n",
    "                \"label_ids\": torch.from_numpy(self.label_ids[idx]).long()\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def get_lengths(self):\n",
    "        return [len(seq) for seq in self.input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BucketBatchSampler(Sampler):\n",
    "    def __init__(self, lengths, batch_size=16, shuffle=True, drop_last=True, bucket_size_multiplier=100):\n",
    "        self.lengths = lengths\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.drop_last = drop_last\n",
    "        self.bucket_size = batch_size * bucket_size_multiplier\n",
    "\n",
    "        self.sorted_indices = np.argsort(lengths)\n",
    "        self.batches = self._create_batches()\n",
    "\n",
    "    def _create_batches(self):\n",
    "        batches = []\n",
    "        for i in range(0, len(self.sorted_indices), self.bucket_size):\n",
    "            bucket = self.sorted_indices[i:i+self.bucket_size]\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(bucket)\n",
    "            for j in range(0, len(bucket), self.batch_size):\n",
    "                batch = bucket[j:j+self.batch_size]\n",
    "                if not self.drop_last or len(batch) == self.batch_size:\n",
    "                    batches.append(batch.tolist())\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(batches)\n",
    "        return batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield from self.batches\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, pad_token_id=0, max_len=None):\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.max_len = max_len  # If None, pad to the longest in batch\n",
    "\n",
    "    def _pad_batch(self, batch_sequences):\n",
    "        input_ids = [sample['input_ids'] for sample in batch_sequences]\n",
    "        label_ids = [sample['label_ids'] for sample in batch_sequences]\n",
    "\n",
    "        input_tensor_seqs = [seq.clone().detach() for seq in input_ids]\n",
    "        label_tensor_seqs = [seq.clone().detach() for seq in label_ids]\n",
    "\n",
    "        if self.max_len:\n",
    "            input_tensor_seqs = [seq[:self.max_len] for seq in input_tensor_seqs]\n",
    "            label_tensor_seqs = [seq[:self.max_len] for seq in label_tensor_seqs]\n",
    "        \n",
    "        padded_input = pad_sequence(input_tensor_seqs, batch_first=True, padding_value=self.pad_token_id)\n",
    "        padded_label = pad_sequence(label_tensor_seqs, batch_first=True, padding_value=self.pad_token_id)\n",
    "\n",
    "        if self.max_len and padded_input.size(1) < self.max_len:\n",
    "            pad_size = self.max_len - padded_input.size(1)\n",
    "            pad_tensor = torch.full((padded_input.size(0), pad_size), self.pad_token_id, dtype=torch.long)\n",
    "            padded_input = torch.cat([padded_input, pad_tensor], dim=1)\n",
    "\n",
    "        if self.max_len and padded_label.size(1) < self.max_len:\n",
    "            pad_size = self.max_len - padded_label.size(1)\n",
    "            pad_tensor = torch.full((padded_label.size(0), pad_size), self.pad_token_id, dtype=torch.long)\n",
    "            padded_label = torch.cat([padded_label, pad_tensor], dim=1)\n",
    "\n",
    "        input_key_padding_mask = (padded_input == self.pad_token_id)  # (batch_size, seq_len)\n",
    "        label_key_padding_mask = (padded_label == self.pad_token_id)\n",
    "\n",
    "        return padded_input.contiguous(), input_key_padding_mask.contiguous(), padded_label.contiguous(), label_key_padding_mask.contiguous()\n",
    "\n",
    "    def __call__(self, batch_sequences):\n",
    "        return self._pad_batch(batch_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, pad_token_id=0):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "        self.pos_embedding = nn.Embedding(512, embed_dim) # max length of 100 for positional encoding\n",
    "\n",
    "    def forward(self, input_ids, key_padding_mask): # input_ids: (batch_size, seq_len)\n",
    "        batch_size, seq_len = input_ids.size()\n",
    "        \n",
    "        token_emb = self.token_embedding(input_ids) * math.sqrt(self.token_embedding.embedding_dim) # (batch_size, seq_len, embed_dim)\n",
    "\n",
    "        pos_emb = self.pos_embedding(torch.arange(seq_len, device=input_ids.device)).unsqueeze(0).expand(batch_size, seq_len, -1) # (batch_size, seq_len, embed_dim)\n",
    "\n",
    "        emb = token_emb + pos_emb\n",
    "\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodingLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super(EncodingLayer, self).__init__()\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        self.layernorm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layernorm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.SiLU(), # using SiLU activation for better performance\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ff_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None):\n",
    "\n",
    "        x_norm = self.layernorm1(x) # layernorm before attention (pre-norm)\n",
    "        attn_y = self.attn(x_norm, x_norm, x_norm, key_padding_mask=key_padding_mask)[0]\n",
    "        x = x + self.dropout(attn_y)\n",
    "\n",
    "\n",
    "        x_norm = self.layernorm2(x) # using pre-norm for stability\n",
    "        ff_output = self.feedforward(x_norm)\n",
    "        x = x + self.dropout(ff_output)\n",
    "\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodingLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super(DecodingLayer, self).__init__()\n",
    "\n",
    "        self.attn1 = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.attn2 = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        self.layernorm1 = nn.LayerNorm(embed_dim)\n",
    "        self.layernorm2 = nn.LayerNorm(embed_dim)\n",
    "        self.layernorm3 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.SiLU(), # using SiLU instead of ReLU for better performance  \n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ff_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encoder_out, tgt_key_padding_mask=None, memory_key_padding_mask=None, causal_mask=None):\n",
    "        if causal_mask is None:\n",
    "            seq_len = x.size(1)\n",
    "            causal_mask = torch.triu(torch.ones(seq_len, seq_len, device=x.device), diagonal=1).bool()\n",
    "\n",
    "        x_norm = self.layernorm1(x) # pre-norm on self attention\n",
    "        masked_attn = self.attn1(x_norm, x_norm, x_norm, attn_mask=causal_mask, key_padding_mask=tgt_key_padding_mask)[0] # masked self attention\n",
    "        x = x + self.dropout(masked_attn)\n",
    "\n",
    "\n",
    "        x_norm = self.layernorm2(x) # pre-norm on cross attention\n",
    "        cross_attn = self.attn2(x_norm, encoder_out, encoder_out, key_padding_mask=memory_key_padding_mask)[0]\n",
    "        x = x + self.dropout(cross_attn)\n",
    "\n",
    "        x_norm = self.layernorm3(x)\n",
    "        ff_output = self.feedforward(x_norm)\n",
    "        x = x + self.dropout(ff_output)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, ff_dim, num_heads,\n",
    "                 max_seq_len=None, n_encoders=2, n_decoders=2, pad_token_id=0, dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "        self.src_embedding = EmbeddingLayer(vocab_size, embed_dim, pad_token_id) # embedding for source\n",
    "        self.tgt_embedding = EmbeddingLayer(vocab_size, embed_dim, pad_token_id) # embedding for target\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([ # stack of encoding layers\n",
    "            EncodingLayer(embed_dim, num_heads, ff_dim, dropout)\n",
    "            for _ in range(n_encoders)\n",
    "        ])\n",
    "\n",
    "        self.decoder_layers = nn.ModuleList([ # stack of decoding layers\n",
    "            DecodingLayer(embed_dim, num_heads, ff_dim, dropout)\n",
    "            for _ in range(n_decoders)\n",
    "        ])\n",
    "\n",
    "        self.decoder_final_norm = nn.LayerNorm(embed_dim) # final layernorm for decoder output\n",
    "\n",
    "        self.output_projection = nn.Linear(embed_dim, vocab_size) # output layer\n",
    "\n",
    "    def encode(self, src_ids, src_key_padding_mask):\n",
    "        x = self.src_embedding(src_ids, src_key_padding_mask)\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x, key_padding_mask=src_key_padding_mask)\n",
    "        return x\n",
    "\n",
    "    def decode(self, tgt_ids, encoder_out, tgt_key_padding_mask, memory_key_padding_mask):\n",
    "        x = self.tgt_embedding(tgt_ids, tgt_key_padding_mask)\n",
    "\n",
    "        seq_len = tgt_ids.size(1)\n",
    "        causal_mask = torch.triu(torch.ones(seq_len, seq_len, device=tgt_ids.device), diagonal=1).bool()\n",
    "\n",
    "        for layer in self.decoder_layers:\n",
    "            x = layer(x, encoder_out, memory_key_padding_mask=memory_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, causal_mask=causal_mask)\n",
    "\n",
    "        x = self.decoder_final_norm(x) # final layernorm for decoder output\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, src_ids, tgt_ids, src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "        encoder_out = self.encode(src_ids, src_key_padding_mask)\n",
    "        decoder_out = self.decode(tgt_ids, encoder_out, tgt_key_padding_mask, src_key_padding_mask)\n",
    "        logits = self.output_projection(decoder_out)\n",
    "        return logits  # (batch_size, tgt_seq_len, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_schedule_with_plateau(warmup_steps=30000, plateau_steps=200000, total_steps=1100000, min_lr_ratio=0.001): # custom cosine schedule with plateau to fit my curriculum learning process\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return current_step / warmup_steps # warmup phase\n",
    "        elif current_step < warmup_steps + plateau_steps:\n",
    "            return 1.0 # plateau phase\n",
    "        else:\n",
    "            progress = (current_step - warmup_steps - plateau_steps) / (total_steps - warmup_steps - plateau_steps)\n",
    "            cosine_decay =  0.5 * (1.0 + math.cos(math.pi * progress)) # decay, cosine annealing\n",
    "            return min_lr_ratio + (1.0 - min_lr_ratio) * cosine_decay # decays down to min_lr_ratio\n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, model, optimizer, preprocessor, load_model_path=None, batch_size=16, device=\"cpu\", save_path=\"best_model.pth\", \n",
    "                 val_filepath=\"../data/tokenized_data_val.csv\", filepath=\"../data/tokenized_data_train.csv\", embed_dim=512,\n",
    "                 max_tokens = 35, batches_per_size=3000,\n",
    "                 num_warmup_steps=33000, num_plateau_steps=200000, num_training_steps=1100000, current_step=0, start_epoch=0):\n",
    "        self.EOS_ID = 3 # this is the EOS token ID in my dataset\n",
    "        self.PAD_ID = 0 # this is the PAD token ID in my dataset\n",
    "        self.BOS_ID = 2 # this is the BOS token ID in my dataset\n",
    "        \n",
    "        self.max_tokens = max_tokens\n",
    "        self.batches_per_size = batches_per_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.filepath=filepath\n",
    "        self.model = model.to(device)\n",
    "        self.start_epoch=start_epoch\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        lr_lambda = cosine_schedule_with_plateau(warmup_steps=num_warmup_steps, plateau_steps=num_plateau_steps, total_steps=num_training_steps)\n",
    "        self.scheduler = LambdaLR(self.optimizer, lr_lambda)\n",
    "\n",
    "        self.current_step = current_step \n",
    "        if current_step > 0:\n",
    "            for _ in range(self.current_step):\n",
    "                self.scheduler.step() # to restart the training without reinitializing the learning rate schedule\n",
    "         \n",
    "        self.preprocessor = preprocessor\n",
    "        self.device = device\n",
    "        self.save_path = save_path\n",
    "\n",
    "        self.val_filepath = val_filepath\n",
    "\n",
    "        self.best_val_loss = float(\"inf\")\n",
    "        self.epochs_without_improvement = 0\n",
    "\n",
    "        self.scaler = torch.amp.GradScaler(\"cuda\") if device == \"cuda\" else None\n",
    "\n",
    "        if load_model_path:\n",
    "            self.model.load_state_dict(torch.load(load_model_path, map_location=self.device))\n",
    "            print(f\"Model loaded from {load_model_path}\")\n",
    "\n",
    "        self.en_tokenizer = spm.SentencePieceProcessor()\n",
    "        self.tr_tokenizer = spm.SentencePieceProcessor()\n",
    "\n",
    "        self.en_tokenizer.load(\"../data/en_spm.model\")\n",
    "        self.tr_tokenizer.load(\"../data/tr_spm.model\")\n",
    "\n",
    "\n",
    "    def greedy_decode(self, input_ids, input_key_padding_mask, max_len):\n",
    "        max_len = min(max_len, 50) # just in case there's some crazy sentence out there\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_size = input_ids.size(0)\n",
    "            device = input_ids.device\n",
    "\n",
    "            decoded = torch.full((batch_size, 1), self.BOS_ID, dtype=torch.long, device=device)\n",
    "            finished = torch.zeros(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "            for step in range(max_len):\n",
    "                logits = self.model(input_ids, decoded, src_key_padding_mask=input_key_padding_mask)\n",
    "                next_token = torch.argmax(logits[:, -1, :], dim=-1, keepdim=True)\n",
    "                decoded = torch.cat([decoded, next_token], dim=1)\n",
    "                finished |= next_token.squeeze(1) == self.EOS_ID\n",
    "                if finished.all():\n",
    "                    break\n",
    "\n",
    "            return decoded\n",
    "\n",
    "\n",
    "    def decode_sequence(self, sequence, tokenizer=None):\n",
    "        if tokenizer is None:\n",
    "            tokenizer = self.tr_tokenizer\n",
    "        tokens = []\n",
    "        for tok in sequence:\n",
    "            if tok == self.EOS_ID:\n",
    "                break\n",
    "            if tok not in {self.BOS_ID, self.PAD_ID}:\n",
    "                tokens.append(tok)\n",
    "        return tokenizer.decode(tokens)\n",
    "\n",
    "    \n",
    "    def compute_bleu(self, reference, hypothesis):\n",
    "        return sacrebleu.sentence_bleu(hypothesis, [reference]).score\n",
    "            \n",
    "\n",
    "    def _run_epoch(self, loader, train=True):\n",
    "        epoch_loss = 0.0\n",
    "        num_nans = 0\n",
    "        bleu_scores = []\n",
    "\n",
    "        last_report = time.time()\n",
    "\n",
    "        if train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "\n",
    "\n",
    "        loader = tqdm.tqdm(loader, desc=\"Training\" if train else \"Validation\", mininterval=10) # Progress bar, updating every 10 seconds to avoid cluttering the output\n",
    "        for batch in loader:\n",
    "            input_ids, input_key_padding_mask, label_ids, label_key_padding_mask = batch\n",
    "            input_ids, input_key_padding_mask = input_ids.to(self.device, non_blocking=True), input_key_padding_mask.to(self.device, non_blocking=True)\n",
    "            label_ids, label_key_padding_mask = label_ids.to(self.device, non_blocking=True), label_key_padding_mask.to(self.device, non_blocking=True)\n",
    "\n",
    "            if input_key_padding_mask.all(dim=1).any():\n",
    "                print(f\"[!] Skipping batch with all-padding input sequence.\")\n",
    "                continue\n",
    "\n",
    "            if label_key_padding_mask.all(dim=1).any():\n",
    "                print(f\"[!] Skipping batch with all-padding target sequence.\")\n",
    "                continue\n",
    "\n",
    "            assert input_ids.shape == input_key_padding_mask.shape, \"masking error with input_ids\"\n",
    "            assert label_ids.shape == label_key_padding_mask.shape, \"masking error with label_ids\"\n",
    "\n",
    "\n",
    "            if train:\n",
    "                self.optimizer.zero_grad(set_to_none=True) # zero the gradients\n",
    "            \n",
    "                #tgt_input = label_ids[:, :-1] # uncomment to go back to regular training\n",
    "                #targets = label_ids[:, 1:] # uncomment to go back to regular training\n",
    "                #tgt_key_padding_mask = label_key_padding_mask[:, :-1] # uncomment to go back to regular training\n",
    "\n",
    "                ##################################################### EXPERIMENTAL PART #####################################################\n",
    "\n",
    "                raw_tgt = label_ids[:, :-1].clone()                      # copy the target sequence\n",
    "                eos_pos = raw_tgt == self.EOS_ID                         # find the position of the EOS token in the target sequence\n",
    "                raw_tgt[eos_pos] = self.PAD_ID                           # replace the EOS token with the PAD token in the target sequence\n",
    "                tgt_input = raw_tgt                                      # use the modified target sequence as input to the decoder\n",
    "                targets    = label_ids[:, 1:]                            # use the original target sequence as targets for the loss function\n",
    "                tgt_key_padding_mask = label_key_padding_mask[:, :-1] | eos_pos # replace the EOS token with the PAD token in the target sequence\n",
    "\n",
    "                # why do we do this? because the model is trained to predict the EOS token, but we don't want it to see the EOS token during teacher forcing.\n",
    "                # this way, it's still penalized for not predicting EOS in cross entropy loss, but it doesn't see the EOS token during teacher forcing.\n",
    "                # if i didn't do this, my auxiliary loss would simply sit in a local minimum where it stops after it sees an EOS token.\n",
    "\n",
    "                ##################################################### EXPERIMENTAL PART END #####################################################\n",
    "\n",
    "                if self.scaler: # to use mixed precision training\n",
    "                    #with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                    with torch.amp.autocast(device_type=\"cuda\", enabled=False): # to disable in case of numerical instability\n",
    "                        logits = self.model(\n",
    "                            input_ids,\n",
    "                            tgt_input,\n",
    "                            src_key_padding_mask=input_key_padding_mask,\n",
    "                            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "                        )\n",
    "                        logits = logits.view(-1, logits.size(-1)) # only running the forward pass with autocast for now, when i add backprop it causes NaN errors\n",
    "\n",
    "                        targets = targets.reshape(-1)\n",
    "\n",
    "                    logits = logits.float() # convert logits to float32 for loss calculation so that float16 values don't sneak in and cause NaN errors\n",
    "                    # loss = self.loss_fn(logits, targets) # this is the original line without a custom loss function\n",
    "\n",
    "                    # below is an implementation of a loss function that doubles the loss for eos tokens, so the model is incentivized to stop at the right time.\n",
    "\n",
    "                    losses = F.cross_entropy(logits, targets, reduction=\"none\", ignore_index=0, label_smoothing=0.1)\n",
    "\n",
    "                    eos_mask = (targets == self.EOS_ID).float()\n",
    "                    weights = 1.0 + eos_mask  # 2 if EOS, else 1, effectively doubling the loss for EOS tokens\n",
    "                    weighted_losses = losses * weights # EOS tokens get double the loss\n",
    "                    loss = weighted_losses.mean() # mean loss over the batch\n",
    "\n",
    "\n",
    "\n",
    "                    ##################################################### EXPERIMENTAL PART #####################################################\n",
    "\n",
    "                    batch_size = input_ids.size(0)\n",
    "                    logits_reshaped = logits.view(batch_size, -1, logits.size(-1))\n",
    "                    eos_probs = F.softmax(logits_reshaped, dim=-1)[..., self.EOS_ID]\n",
    "\n",
    "                    seq_len =eos_probs.size(1)\n",
    "                    positions = torch.arange(seq_len, device=self.device).float().unsqueeze(0).expand(batch_size, -1)\n",
    "                    true_eos_pos = (label_ids == self.EOS_ID).int().argmax(dim=1).unsqueeze(1) \n",
    "\n",
    "                    ramp_mask = positions < true_eos_pos # positions where the EOS probability should be getting ramped up as we approach the end of the sentence.\n",
    "                    peak_mask = positions == true_eos_pos # the true EOS position\n",
    "                    tail_mask = positions > true_eos_pos # tail of the output, i.e. padded positions\n",
    "\n",
    "                    rel_diffs = (positions - true_eos_pos) / (true_eos_pos + 1e-6)\n",
    "\n",
    "                    ramp = torch.exp(-(rel_diffs ** 2) / (2 * 0.05 ** 2)) * ramp_mask \n",
    "                    peak = peak_mask.float()\n",
    "                    tail = tail_mask.float() # need exactly eos at the padded positions as well, since we don't feed EOS during teacher forcing the model constantly gets the finished sentence it needs to add EOS to.\n",
    "\n",
    "                    target = (ramp + peak + tail) * 0.9 # because of label smoothing, the target probability is 0.9 at the correct positions, not 1.\n",
    "                    target = target / (target.sum(dim=1, keepdim=True) + 1e-8) # final target distribution\n",
    "                    eos_probs = eos_probs / (eos_probs.sum(dim=1, keepdim=True) + 1e-8) # the real distribution is normalized too\n",
    "\n",
    "                    eos_loss = F.kl_div(eos_probs.log(), target, reduction='batchmean').clamp(max=10) # KL divergence calculates a differentiable loss, comparing the divergence between the two distributions\n",
    "\n",
    "                    total_loss = eos_loss + loss\n",
    "                    \n",
    "                    ##################################################### EXPERIMENTAL PART END #####################################################\n",
    "\n",
    "\n",
    "\n",
    "                    #if torch.isnan(loss).any() or torch.isinf(loss).any() or loss.item() > 1e3: unexperimental\n",
    "                    if torch.isnan(total_loss).any() or torch.isinf(total_loss).any() or total_loss.item() > 1e3:\n",
    "                        print(f\"[!] Skipping batch with NaN/Inf/unusually large loss. Input IDs shape: {input_ids.shape}\")\n",
    "                        self.optimizer.zero_grad()\n",
    "                        num_nans += 1\n",
    "                        continue\n",
    "\n",
    "                    #epoch_loss += loss.item()\n",
    "                    epoch_loss += total_loss.item() # uncomment the above line to use the original loss function\n",
    "\n",
    "                    main_loss = loss.item() # for logging purposes, the original loss function\n",
    "                    aux_loss = eos_loss.item() # for logging purposes, the experimental loss function\n",
    "\n",
    "                    self.scaler.scale(total_loss).backward() # Backpropagation\n",
    "\n",
    "                    nan_grad = False\n",
    "                    for name, param in self.model.named_parameters():\n",
    "                        if param.grad is not None:\n",
    "                            if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():\n",
    "                                print(f\"[!] Skipping batch with NaN/Inf gradient in {name}\")\n",
    "                                num_nans += 1\n",
    "                                \n",
    "                                nan_grad = True\n",
    "                                break\n",
    "                    if nan_grad:\n",
    "                        self.optimizer.zero_grad()\n",
    "                        continue\n",
    "\n",
    "                    if num_nans > 15:\n",
    "                        send_message(content=f\"Too many NaN/Inf gradients. Stopping training.\")\n",
    "                        raise RuntimeError(\"Too many NaN/Inf gradients. Stopping training.\")\n",
    "                    \n",
    "\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.5) # gradient clipping, since the model is fairly large\n",
    "\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "\n",
    "                    self.scheduler.step()\n",
    "\n",
    "                    loader.set_postfix(main_loss=main_loss, eos_loss=aux_loss) # Update progress bar\n",
    "                    \n",
    "                else:\n",
    "                    logits = self.model(\n",
    "                        input_ids,\n",
    "                        tgt_input,\n",
    "                        src_key_padding_mask=input_key_padding_mask,\n",
    "                        tgt_key_padding_mask=tgt_key_padding_mask\n",
    "                    )\n",
    "                    logits = logits.view(-1, logits.size(-1)) \n",
    "                    targets = targets.reshape(-1)\n",
    "\n",
    "                    losses = F.cross_entropy(logits, targets, reduction=\"none\", ignore_index=0, label_smoothing=0.1)\n",
    "\n",
    "                    eos_mask = (targets == self.EOS_ID).float()\n",
    "                    weights = 1.0 + eos_mask  # 2 if EOS, else 1\n",
    "                    weighted_losses = losses * weights # EOS tokens get double the loss\n",
    "                    loss = weighted_losses.mean() # mean loss over the batch\n",
    "\n",
    "                    epoch_loss += loss.item()\n",
    "\n",
    "                    loss.backward() # Backpropagation\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.5) # gradient clipping, since the model is fairly large\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    self.scheduler.step() # update learning rate each step\n",
    "\n",
    "                    loader.set_postfix(loss=loss.item()) # Update progress bar\n",
    "\n",
    "\n",
    "                now = time.time()\n",
    "\n",
    "                if now - last_report >= 10*60: # report every 10 minutes\n",
    "                    send_message(tqdm_obj=loader)\n",
    "                    last_report = now\n",
    "            \n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    tgt_input = label_ids[:, :-1]\n",
    "                    targets = label_ids[:, 1:]\n",
    "                    tgt_key_padding_mask = label_key_padding_mask[:, :-1]\n",
    "\n",
    "                    logits = self.model(\n",
    "                        input_ids,\n",
    "                        tgt_input,\n",
    "                        src_key_padding_mask=input_key_padding_mask,\n",
    "                        tgt_key_padding_mask=tgt_key_padding_mask\n",
    "                    )\n",
    "                    logits = logits.view(-1, logits.size(-1))\n",
    "                    targets = targets.reshape(-1)\n",
    "                    \n",
    "                    losses = F.cross_entropy(logits, targets, reduction=\"none\", ignore_index=0, label_smoothing=0.1)\n",
    "\n",
    "                    eos_mask = (targets == self.EOS_ID).float()\n",
    "                    weights = 1.0 + eos_mask  # 2 if EOS, else 1\n",
    "                    weighted_losses = losses * weights # EOS tokens get double the loss\n",
    "                    loss = weighted_losses.mean() # mean loss over the batch\n",
    "\n",
    "                    #### BLEU score calculation #####\n",
    "                    if random.random() < 0.025:  # 2.5% of batches\n",
    "                        max_len = (label_ids != 0).sum(dim=1).max().item()  # length cap based on label lengths\n",
    "                        predictions = self.greedy_decode(input_ids, input_key_padding_mask, max_len)\n",
    "\n",
    "                        for i in range(min(len(predictions), 3)):  # limit examples per batch\n",
    "                            pred_text = self.decode_sequence(predictions[i].tolist())\n",
    "                            true_text = self.decode_sequence(label_ids[i].tolist())\n",
    "\n",
    "                            bleu = self.compute_bleu(true_text, pred_text)\n",
    "                            bleu_scores.append(bleu)\n",
    "\n",
    "                    epoch_loss += loss.item()\n",
    "\n",
    "                loader.set_postfix(loss=loss.item())\n",
    "\n",
    "        if len(loader) > 0:\n",
    "            if not train:\n",
    "                avg_bleu = sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0.0\n",
    "                if bleu_scores:\n",
    "                    print(f\"Average BLEU score this epoch: {avg_bleu:.4f}, with {len(bleu_scores)} samples.\")\n",
    "                    send_message(content=f\"🟢 Validation BLEU: {avg_bleu:.4f} ({len(bleu_scores)} samples)\")\n",
    "                else:\n",
    "                    print(\"[BLEU] No samples chosen this epoch for BLEU calculation.\")\n",
    "                    send_message(content=\"[BLEU] No samples chosen this epoch for BLEU calculation.\")\n",
    "            return epoch_loss / len(loader)\n",
    "        else:\n",
    "            return epoch_loss\n",
    "\n",
    "    def train(self, num_epochs=50, patience=5, verbose=True):\n",
    "        try:\n",
    "            done_steps = self.current_step\n",
    "            \n",
    "            for epoch in range(self.start_epoch, num_epochs):\n",
    "                if self.max_tokens + epoch <= 20:\n",
    "                    max_tok = self.max_tokens + epoch\n",
    "                else:\n",
    "                    max_tok = min((epoch + self.max_tokens - 20)*2 + 20, 35) # faster increase after basic structures are learned\n",
    "                    \n",
    "\n",
    "                train_dataset = DatasetFromCSV(filepath=self.filepath, mode=\"train\", \n",
    "                                               batches_per_size=self.batches_per_size,\n",
    "                                               max_tokens=max_tok, # max length of 40 because my system is trash\n",
    "                                               batch_size=self.batch_size\n",
    "                )\n",
    "\n",
    "                train_loader = DataLoader(\n",
    "                    dataset=train_dataset,\n",
    "                    batch_sampler=BucketBatchSampler(train_dataset.get_lengths(), batch_size=self.batch_size, shuffle=True),\n",
    "                    collate_fn=self.preprocessor,\n",
    "                    pin_memory=True\n",
    "                )\n",
    "\n",
    "                print(f\"Loaded {len(train_loader)} batches of training data. Starting epoch {epoch+1}/{num_epochs}... (Current LR: {self.scheduler.get_last_lr()[0]:.8f})\")\n",
    "                send_message(\n",
    "                    content=(\n",
    "                        f\"🟡 Epoch {epoch+1}/{num_epochs} started\\n\"\n",
    "                        f\"🔹 Batches: {len(train_loader)}\\n\"\n",
    "                        f\"🔹 Max Tokens: {max_tok} | Batch Size: {self.batch_size} | Batches/Size: {self.batches_per_size}\\n\"\n",
    "                        f\"🚀 LR: {self.scheduler.get_last_lr()[0]:.8f}\\n\"\n",
    "                        f\"🔁 Steps Done: {done_steps}\"\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                train_loss = self._run_epoch(train_loader, train=True)\n",
    "                done_steps += len(train_loader)\n",
    "\n",
    "                del train_loader, train_dataset # clear the memory\n",
    "                torch.cuda.empty_cache() # clear the cache to avoid OOM errors\n",
    "\n",
    "                val_dataset = DatasetFromCSV(filepath=self.val_filepath, mode=\"val\", batches_per_size=self.batches_per_size, batch_size=self.batch_size)\n",
    "\n",
    "                val_loader = DataLoader(\n",
    "                    dataset=val_dataset,\n",
    "                    batch_sampler=BucketBatchSampler(val_dataset.get_lengths(), batch_size=self.batch_size, shuffle=True),\n",
    "                    collate_fn=self.preprocessor,\n",
    "                    pin_memory=True\n",
    "                )\n",
    "\n",
    "                val_loss = self._run_epoch(val_loader, train=False)\n",
    "\n",
    "                current_lr = self.scheduler.get_last_lr()[0]\n",
    "                if verbose:\n",
    "                    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "                    print(f\"  Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Current Learning Rate: {current_lr:.8f}\") \n",
    "\n",
    "                if val_loss < self.best_val_loss:\n",
    "                    self.best_val_loss = val_loss\n",
    "                    self.epochs_without_improvement = 0\n",
    "                    torch.save(self.model.state_dict(), self.save_path)\n",
    "                    if verbose:\n",
    "                        print(f\"Best model saved to {self.save_path}.\")\n",
    "                else:\n",
    "                    self.epochs_without_improvement += 1\n",
    "\n",
    "                if self.epochs_without_improvement >= patience:\n",
    "                    if verbose:\n",
    "                        print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "                del val_loader, val_dataset # clear the memory\n",
    "                torch.cuda.empty_cache() # clear the cache to avoid OOM errors\n",
    "                if verbose:\n",
    "                    print(  f\"🟡 Epoch {epoch+1}/{num_epochs} finished\\n\"\n",
    "                            f\"🔹 Max Tokens: {max_tok} | Batch Size: {self.batch_size} | Batches/Size: {self.batches_per_size}\\n\"\n",
    "                            f\"🚀 LR: {current_lr:.8f}\\n\"\n",
    "                            f\"🔁 Steps Done: {done_steps}\"\n",
    "                            f\"  Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\"\n",
    "                            )\n",
    "\n",
    "                send_message(embed=make_embed(epoch+1, train_loss, val_loss, current_lr, done_steps, max_tok, self.batches_per_size))\n",
    "\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nTraining interrupted by user. Saving checkpoint...\")\n",
    "            torch.save(self.model.state_dict(), \"checkpoint.pth\")\n",
    "            if verbose:\n",
    "                print(\"Checkpoint model saved.\")\n",
    "\n",
    "# pad_id=0, unk_id=1, bos_id=2, eos_id=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(self):\n",
    "    for name, module in self.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if name == \"output_projection\":\n",
    "                nn.init.normal_(module.weight, mean=0, std=0.02)\n",
    "            else:\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0, std=0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DatasetFromCSV] Loaded 2632 examples up to 3 tokens from 3.\n",
      "Loaded 164 batches of training data. Starting epoch 1/50... (Current LR: 0.00000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 164/164 [00:26<00:00,  6.18it/s, eos_loss=2, main_loss=11]     \n",
      "Validation: 100%|██████████| 12648/12648 [06:30<00:00, 32.40it/s, loss=7.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score this epoch: 0.0154, with 396 samples.\n",
      "Epoch 1/50\n",
      "  Train Loss: 11.0087, Val Loss: 7.3270, Current Learning Rate: 0.00000044\n",
      "Best model saved to best_model.pth.\n",
      "🟡 Epoch 1/50 finished\n",
      "🔹 Max Tokens: 3 | Batch Size: 16 | Batches/Size: 2500\n",
      "🚀 LR: 0.00000044\n",
      "🔁 Steps Done: 164  Train Loss: 11.0087, Val Loss: 7.3270\n",
      "[DatasetFromCSV] Loaded 42632 examples up to 4 tokens from 3.\n",
      "Loaded 2664 batches of training data. Starting epoch 2/50... (Current LR: 0.00000044)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2664/2664 [06:59<00:00,  6.35it/s, eos_loss=1.81, main_loss=3.33]\n",
      "Validation: 100%|██████████| 12648/12648 [05:57<00:00, 35.42it/s, loss=6.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score this epoch: 1.6148, with 294 samples.\n",
      "Epoch 2/50\n",
      "  Train Loss: 7.1118, Val Loss: 6.3777, Current Learning Rate: 0.00000754\n",
      "Best model saved to best_model.pth.\n",
      "🟡 Epoch 2/50 finished\n",
      "🔹 Max Tokens: 4 | Batch Size: 16 | Batches/Size: 2500\n",
      "🚀 LR: 0.00000754\n",
      "🔁 Steps Done: 2828  Train Loss: 7.1118, Val Loss: 6.3777\n",
      "[DatasetFromCSV] Loaded 82632 examples up to 5 tokens from 3.\n",
      "Loaded 5164 batches of training data. Starting epoch 3/50... (Current LR: 0.00000754)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5164/5164 [13:42<00:00,  6.28it/s, eos_loss=1.41, main_loss=4.65] \n",
      "Validation: 100%|██████████| 12648/12648 [06:45<00:00, 31.23it/s, loss=4.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score this epoch: 1.6961, with 441 samples.\n",
      "Epoch 3/50\n",
      "  Train Loss: 6.1656, Val Loss: 5.7435, Current Learning Rate: 0.00002131\n",
      "Best model saved to best_model.pth.\n",
      "🟡 Epoch 3/50 finished\n",
      "🔹 Max Tokens: 5 | Batch Size: 16 | Batches/Size: 2500\n",
      "🚀 LR: 0.00002131\n",
      "🔁 Steps Done: 7992  Train Loss: 6.1656, Val Loss: 5.7435\n",
      "[DatasetFromCSV] Loaded 122632 examples up to 6 tokens from 3.\n",
      "Loaded 7664 batches of training data. Starting epoch 4/50... (Current LR: 0.00002131)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7664/7664 [20:16<00:00,  6.30it/s, eos_loss=0.907, main_loss=4.34]\n",
      "Validation: 100%|██████████| 12648/12648 [06:13<00:00, 33.86it/s, loss=5.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score this epoch: 3.0305, with 324 samples.\n",
      "Epoch 4/50\n",
      "  Train Loss: 5.5767, Val Loss: 5.4267, Current Learning Rate: 0.00004175\n",
      "Best model saved to best_model.pth.\n",
      "🟡 Epoch 4/50 finished\n",
      "🔹 Max Tokens: 6 | Batch Size: 16 | Batches/Size: 2500\n",
      "🚀 LR: 0.00004175\n",
      "🔁 Steps Done: 15656  Train Loss: 5.5767, Val Loss: 5.4267\n",
      "[DatasetFromCSV] Loaded 162632 examples up to 7 tokens from 3.\n",
      "Loaded 10164 batches of training data. Starting epoch 5/50... (Current LR: 0.00004175)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10164/10164 [27:04<00:00,  6.26it/s, eos_loss=0.365, main_loss=3.41]\n",
      "Validation: 100%|██████████| 12648/12648 [06:00<00:00, 35.08it/s, loss=4.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score this epoch: 5.8790, with 381 samples.\n",
      "Epoch 5/50\n",
      "  Train Loss: 4.7826, Val Loss: 5.0413, Current Learning Rate: 0.00006885\n",
      "Best model saved to best_model.pth.\n",
      "🟡 Epoch 5/50 finished\n",
      "🔹 Max Tokens: 7 | Batch Size: 16 | Batches/Size: 2500\n",
      "🚀 LR: 0.00006885\n",
      "🔁 Steps Done: 25820  Train Loss: 4.7826, Val Loss: 5.0413\n",
      "[DatasetFromCSV] Loaded 202632 examples up to 8 tokens from 3.\n",
      "Loaded 12664 batches of training data. Starting epoch 6/50... (Current LR: 0.00006885)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12664/12664 [33:21<00:00,  6.33it/s, eos_loss=0.414, main_loss=2.74] \n",
      "Validation: 100%|██████████| 12648/12648 [06:15<00:00, 33.67it/s, loss=3.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score this epoch: 7.6645, with 342 samples.\n",
      "Epoch 6/50\n",
      "  Train Loss: 4.0616, Val Loss: 4.6823, Current Learning Rate: 0.00010000\n",
      "Best model saved to best_model.pth.\n",
      "🟡 Epoch 6/50 finished\n",
      "🔹 Max Tokens: 8 | Batch Size: 16 | Batches/Size: 2500\n",
      "🚀 LR: 0.00010000\n",
      "🔁 Steps Done: 38484  Train Loss: 4.0616, Val Loss: 4.6823\n",
      "[DatasetFromCSV] Loaded 242632 examples up to 9 tokens from 3.\n",
      "Loaded 15164 batches of training data. Starting epoch 7/50... (Current LR: 0.00010000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15164/15164 [40:17<00:00,  6.27it/s, eos_loss=0.443, main_loss=1.97] \n",
      "Validation: 100%|██████████| 12648/12648 [06:02<00:00, 34.90it/s, loss=5.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score this epoch: 7.1559, with 378 samples.\n",
      "Epoch 7/50\n",
      "  Train Loss: 3.6418, Val Loss: 4.4253, Current Learning Rate: 0.00010000\n",
      "Best model saved to best_model.pth.\n",
      "🟡 Epoch 7/50 finished\n",
      "🔹 Max Tokens: 9 | Batch Size: 16 | Batches/Size: 2500\n",
      "🚀 LR: 0.00010000\n",
      "🔁 Steps Done: 53648  Train Loss: 3.6418, Val Loss: 4.4253\n",
      "[DatasetFromCSV] Loaded 282632 examples up to 10 tokens from 3.\n",
      "Loaded 17664 batches of training data. Starting epoch 8/50... (Current LR: 0.00010000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 17664/17664 [46:36<00:00,  6.32it/s, eos_loss=0.64, main_loss=2.42]  \n",
      "Validation: 100%|██████████| 12648/12648 [06:02<00:00, 34.92it/s, loss=3.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score this epoch: 9.5702, with 381 samples.\n",
      "Epoch 8/50\n",
      "  Train Loss: 3.3848, Val Loss: 4.1459, Current Learning Rate: 0.00010000\n",
      "Best model saved to best_model.pth.\n",
      "🟡 Epoch 8/50 finished\n",
      "🔹 Max Tokens: 10 | Batch Size: 16 | Batches/Size: 2500\n",
      "🚀 LR: 0.00010000\n",
      "🔁 Steps Done: 71312  Train Loss: 3.3848, Val Loss: 4.1459\n",
      "[DatasetFromCSV] Loaded 322632 examples up to 11 tokens from 3.\n",
      "Loaded 20164 batches of training data. Starting epoch 9/50... (Current LR: 0.00010000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20164/20164 [53:03<00:00,  6.33it/s, eos_loss=0.213, main_loss=1.74]  \n",
      "Validation: 100%|██████████| 12648/12648 [05:59<00:00, 35.17it/s, loss=3.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score this epoch: 9.2313, with 345 samples.\n",
      "Epoch 9/50\n",
      "  Train Loss: 3.2497, Val Loss: 3.8751, Current Learning Rate: 0.00010000\n",
      "Best model saved to best_model.pth.\n",
      "🟡 Epoch 9/50 finished\n",
      "🔹 Max Tokens: 11 | Batch Size: 16 | Batches/Size: 2500\n",
      "🚀 LR: 0.00010000\n",
      "🔁 Steps Done: 91476  Train Loss: 3.2497, Val Loss: 3.8751\n",
      "[DatasetFromCSV] Loaded 362632 examples up to 12 tokens from 3.\n",
      "Loaded 22664 batches of training data. Starting epoch 10/50... (Current LR: 0.00010000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 22664/22664 [59:54<00:00,  6.31it/s, eos_loss=0.158, main_loss=2.54]  \n",
      "Validation: 100%|██████████| 12648/12648 [05:52<00:00, 35.90it/s, loss=3.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score this epoch: 13.6401, with 318 samples.\n",
      "Epoch 10/50\n",
      "  Train Loss: 3.1676, Val Loss: 3.6995, Current Learning Rate: 0.00010000\n",
      "Best model saved to best_model.pth.\n",
      "🟡 Epoch 10/50 finished\n",
      "🔹 Max Tokens: 12 | Batch Size: 16 | Batches/Size: 2500\n",
      "🚀 LR: 0.00010000\n",
      "🔁 Steps Done: 114140  Train Loss: 3.1676, Val Loss: 3.6995\n",
      "[DatasetFromCSV] Loaded 402632 examples up to 13 tokens from 3.\n",
      "Loaded 25164 batches of training data. Starting epoch 11/50... (Current LR: 0.00010000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 25164/25164 [1:06:25<00:00,  6.31it/s, eos_loss=0.485, main_loss=3.28] \n",
      "Validation: 100%|██████████| 12648/12648 [06:04<00:00, 34.74it/s, loss=4.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score this epoch: 12.8229, with 360 samples.\n",
      "Epoch 11/50\n",
      "  Train Loss: 3.0928, Val Loss: 3.5049, Current Learning Rate: 0.00010000\n",
      "Best model saved to best_model.pth.\n",
      "🟡 Epoch 11/50 finished\n",
      "🔹 Max Tokens: 13 | Batch Size: 16 | Batches/Size: 2500\n",
      "🚀 LR: 0.00010000\n",
      "🔁 Steps Done: 139304  Train Loss: 3.0928, Val Loss: 3.5049\n",
      "\n",
      "Training interrupted by user. Saving checkpoint...\n",
      "Checkpoint model saved.\n"
     ]
    }
   ],
   "source": [
    "# Starting from zero:\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocessor = Preprocessor(pad_token_id=0)\n",
    "    model = Transformer(vocab_size=50000, n_encoders=5, n_decoders=5, embed_dim=512, ff_dim=2048, num_heads=8, dropout=0.2)\n",
    "    model.apply(init_weights) # initialize weights\n",
    "    optimizer = AdamW(model.parameters(), \n",
    "                    lr=0.0001,\n",
    "                    weight_decay=0.01)\n",
    "\n",
    "    trainer = ModelTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        preprocessor=preprocessor,\n",
    "        batch_size=16, # trash gpu\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        save_path=\"best_model.pth\",\n",
    "        max_tokens=3, # starting from a very easy point\n",
    "        batches_per_size=2500, # number of batches per size\n",
    "        num_training_steps=1000000, # total number of training steps\n",
    "        num_warmup_steps=37500, # number of warmup steps for learning rate scheduler\n",
    "        num_plateau_steps=150000, # number of plateau steps for learning rate scheduler\n",
    "    )\n",
    "\n",
    "    trainer.train(num_epochs=50, patience=25, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from best_model.pth\n",
      "[DatasetFromCSV] Loaded 1282632 examples up to 35 tokens from 3.\n",
      "Loaded 80164 batches of training data. Starting epoch 32/75... (Current LR: 0.00000000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80164/80164 [5:19:38<00:00,  4.18it/s, eos_loss=0.0721, main_loss=2.3]     \n",
      "Validation: 100%|██████████| 16021/16021 [10:04<00:00, 26.49it/s, loss=1.3]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score this epoch: 27.4254, with 1152 samples.\n",
      "Epoch 32/75\n",
      "  Train Loss: 2.2616, Val Loss: 2.1962, Current Learning Rate: 0.00010000\n",
      "Best model saved to best_model.pth.\n",
      "🟡 Epoch 32/75 finished\n",
      "🔹 Max Tokens: 35 | Batch Size: 16 | Batches/Size: 2500\n",
      "🚀 LR: 0.00010000\n",
      "🔁 Steps Done: 80164  Train Loss: 2.2616, Val Loss: 2.1962\n",
      "[DatasetFromCSV] Loaded 1282632 examples up to 35 tokens from 3.\n",
      "Loaded 80164 batches of training data. Starting epoch 33/75... (Current LR: 0.00010000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80164/80164 [6:30:39<00:00,  3.42it/s, eos_loss=0.0907, main_loss=2.71]    \n",
      "Validation: 100%|██████████| 16021/16021 [10:25<00:00, 25.60it/s, loss=1.95] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score this epoch: 29.0399, with 1155 samples.\n",
      "Epoch 33/75\n",
      "  Train Loss: 2.2545, Val Loss: 2.1831, Current Learning Rate: 0.00010000\n",
      "Best model saved to best_model.pth.\n",
      "🟡 Epoch 33/75 finished\n",
      "🔹 Max Tokens: 35 | Batch Size: 16 | Batches/Size: 2500\n",
      "🚀 LR: 0.00010000\n",
      "🔁 Steps Done: 160328  Train Loss: 2.2545, Val Loss: 2.1831\n",
      "[DatasetFromCSV] Loaded 1282632 examples up to 35 tokens from 3.\n",
      "Loaded 80164 batches of training data. Starting epoch 34/75... (Current LR: 0.00010000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|█████▎    | 42315/80164 [2:39:18<1:59:28,  5.28it/s, eos_loss=0.0645, main_loss=2.5]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▌    | 44988/80164 [2:48:28<1:50:32,  5.30it/s, eos_loss=0.0698, main_loss=2.61] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 45965/80164 [2:52:02<2:26:34,  3.89it/s, eos_loss=0.174, main_loss=2.03]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 46574/80164 [2:54:28<2:01:56,  4.59it/s, eos_loss=0.0708, main_loss=1.7]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|█████▉    | 47267/80164 [2:57:08<1:57:35,  4.66it/s, eos_loss=0.0331, main_loss=2.31] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|█████▉    | 47328/80164 [2:57:10<1:55:40,  4.73it/s, eos_loss=0.116, main_loss=3.09] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  59%|█████▉    | 47688/80164 [2:58:26<1:46:22,  5.09it/s, eos_loss=0.0602, main_loss=2.32] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|█████▉    | 48042/80164 [2:59:40<1:54:18,  4.68it/s, eos_loss=0.067, main_loss=2.4]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|█████▉    | 48042/80164 [2:59:44<1:54:18,  4.68it/s, eos_loss=0.0163, main_loss=1.76]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 48250/80164 [3:00:27<1:55:53,  4.59it/s, eos_loss=0.0146, main_loss=1.92] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|██████    | 48593/80164 [3:01:47<1:52:44,  4.67it/s, eos_loss=0.0239, main_loss=2.13] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|██████    | 48747/80164 [3:02:16<1:53:06,  4.63it/s, eos_loss=0.0101, main_loss=1.28] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|██████▏   | 49186/80164 [3:03:44<1:43:22,  4.99it/s, eos_loss=0.201, main_loss=2.4]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|██████▏   | 49232/80164 [3:03:56<1:48:14,  4.76it/s, eos_loss=0.0554, main_loss=2.02]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|██████▏   | 49275/80164 [3:04:07<1:53:19,  4.54it/s, eos_loss=0.119, main_loss=1.71] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 49662/80164 [3:05:33<2:01:05,  4.20it/s, eos_loss=0.335, main_loss=2.25]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Skipping batch with NaN/Inf gradient in src_embedding.token_embedding.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 49689/80164 [3:05:33<1:53:48,  4.46it/s, eos_loss=0.335, main_loss=2.25]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Too many NaN/Inf gradients. Stopping training.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 27\u001b[0m\n\u001b[0;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m AdamW(model\u001b[38;5;241m.\u001b[39mparameters(), \n\u001b[0;32m      7\u001b[0m                 lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m,\n\u001b[0;32m      8\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m     10\u001b[0m trainer \u001b[38;5;241m=\u001b[39m ModelTrainer(\n\u001b[0;32m     11\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     start_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m31\u001b[39m, \u001b[38;5;66;03m# specify the epoch to start from (0-indexed)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 27\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain(num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m75\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[12], line 362\u001b[0m, in \u001b[0;36mModelTrainer.train\u001b[1;34m(self, num_epochs, patience, verbose)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m batches of training data. Starting epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m... (Current LR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mget_last_lr()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.8f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    352\u001b[0m send_message(\n\u001b[0;32m    353\u001b[0m     content\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    354\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🟡 Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m started\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    359\u001b[0m     )\n\u001b[0;32m    360\u001b[0m )\n\u001b[1;32m--> 362\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_epoch(train_loader, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    363\u001b[0m done_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m train_loader, train_dataset \u001b[38;5;66;03m# clear the memory\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[12], line 229\u001b[0m, in \u001b[0;36mModelTrainer._run_epoch\u001b[1;34m(self, loader, train)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_nans \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m15\u001b[39m:\n\u001b[0;32m    228\u001b[0m     send_message(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many NaN/Inf gradients. Stopping training.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many NaN/Inf gradients. Stopping training.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39munscale_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer)\n\u001b[0;32m    233\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;66;03m# gradient clipping, since the model is fairly large\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Too many NaN/Inf gradients. Stopping training."
     ]
    }
   ],
   "source": [
    "# To continue training the best model so far (from the end of the last completed epoch):\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocessor = Preprocessor(pad_token_id=0)\n",
    "    model = Transformer(vocab_size=50000, n_encoders=5, n_decoders=5, embed_dim=512, ff_dim=2048, num_heads=8, dropout=0.1)\n",
    "    optimizer = AdamW(model.parameters(), \n",
    "                    lr=0.0001,\n",
    "                    weight_decay=0.01)\n",
    "\n",
    "    trainer = ModelTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        preprocessor=preprocessor,\n",
    "        batch_size=16, # trash gpu\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        save_path=\"best_model.pth\",\n",
    "        load_model_path=\"best_model.pth\",  # Specify the path to the saved model\n",
    "        max_tokens=3, # starting point\n",
    "        batches_per_size=2500, # number of batches per size\n",
    "        num_training_steps=840000, # total number of training steps\n",
    "        num_warmup_steps=0, # number of warmup steps for learning rate scheduler\n",
    "        num_plateau_steps=40000, # number of plateau steps for learning rate scheduler\n",
    "        current_step=0, # to go back to the correct optimizer state\n",
    "        start_epoch=31, # specify the epoch to start from (0-indexed)\n",
    "    )\n",
    "\n",
    "    trainer.train(num_epochs=75, patience=8, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\takns\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from checkpoint.pth\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.12.7)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# to continue from a checkpoint:\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocessor = Preprocessor(pad_token_id=0)\n",
    "    model = Transformer(vocab_size=50000, n_encoders=5, n_decoders=5, embed_dim=512, ff_dim=2048, num_heads=8, dropout=0.1)\n",
    "    optimizer = AdamW(model.parameters(), \n",
    "                    lr=0.000094,\n",
    "                    weight_decay=0.01)\n",
    "\n",
    "    trainer = ModelTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        preprocessor=preprocessor,\n",
    "        batch_size=16,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        save_path=\"best_model.pth\",\n",
    "        load_model_path=\"checkpoint.pth\",\n",
    "        max_tokens=3, # starting point\n",
    "        batches_per_size=2500, # number of batches per size\n",
    "        num_training_steps=1850000, # total number of training steps\n",
    "        num_warmup_steps=10000, # number of warmup steps for learning rate scheduler\n",
    "        num_plateau_steps=1200000, # number of plateau steps for learning rate scheduler\n",
    "        current_step=1150000, # to go back to the correct optimizer state\n",
    "        start_epoch=30, # specify the epoch to start from (0-indexed)\n",
    "    )\n",
    "\n",
    "    trainer.train(num_epochs=70, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to test with fake data\n",
    "\n",
    "def generate_random_sequence(min_length=3, max_length=25, vocab_size=50000):\n",
    "    length = np.random.randint(min_length, max_length + 1)\n",
    "    sequence = \" \".join(map(str, np.random.randint(1, vocab_size, size=length)))\n",
    "    return sequence\n",
    "\n",
    "def generate_fake_data(num_examples=10000, min_length=5, max_length=20, vocab_size=50000):\n",
    "    data = {\n",
    "        \"input_ids\": [\"1 \" + generate_random_sequence(min_length, max_length, vocab_size) + \" 2\" for _ in range(num_examples)]\n",
    "    }\n",
    "    data[\"label_ids\"] = [seq for seq in data[\"input_ids\"]]\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "fake_data = generate_fake_data(num_examples=10000, min_length=5, max_length=20, vocab_size=1000)\n",
    "\n",
    "fake_data.to_csv(\"test_small.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocessor = Preprocessor(pad_token_id=0)\n",
    "    model = Transformer(vocab_size=50000, n_encoders=4, n_decoders=4, embed_dim=512, ff_dim=2048, num_heads=8)\n",
    "    optimizer = AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    trainer = ModelTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        preprocessor=preprocessor,\n",
    "        batch_size=32,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        save_path=\"worse_model.pth\",\n",
    "        val_filepath=\"test_small.csv\", \n",
    "        filepath=\"test_small.csv\",\n",
    "        sample_frac=1\n",
    "    )\n",
    "\n",
    "    trainer.train(num_epochs=50, patience=5, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
